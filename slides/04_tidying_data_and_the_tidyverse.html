<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tidying data and the tidyverse including the pipe.</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emma Rand" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="..\css_files\emma.css" type="text/css" />
    <link rel="stylesheet" href="..\css_files\emma-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Tidying data and the tidyverse including the pipe.
## White Rose BBSRC DTP Training: An Introduction to Reproducible Analyses in R.
### Emma Rand
### University of York, UK

---












# Introduction

## Aims

The aim of this section is to introduce you to the tidyverse &lt;a name=cite-Wickham2019-ml&gt;&lt;/a&gt;([Wickham Averick, et al., 2019](#bib-Wickham2019-ml)) including the pipe, `%&gt;%`  and some commonly applied data tidying operations. We are covering data tidying before the [Advanced Data Import](05_advanced_data_import.html) section because some of the import methods will make use of tidyverse methods and generate tidy data structures.

## Learning outcomes 

The successful student will be able to:

* use the tidyverse
* use pipes to link operations together.  
* carry out some common data tidying tasks such as reshaping, renaming and recoding variables, and cleaning cell contents
 

### ðŸŽ¬ An instruction to do something!!

---
# Data tidying tasks

Tidying data includes reshaping it in to 'tidy' format but also other tasks such as:

* renaming variables for consistency  
* recoding variables  
* cleaning content for consistency with respect to valid values, missing values and NA  

--

ðŸ‘€ 

* Keep the raw data exactly as it came to you and do not alter/edit.
* Script and document all tidying tasks.

---
# Tidyverse

The [tidyverse](https://www.tidyverse.org/) &lt;a name=cite-R-tidyverse&gt;&lt;/a&gt;([Wickham, 2017](#bib-R-tidyverse)) is "an opinionated" collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.  

This consistency is intended to make data work more efficient.

--

The are many other extremely useful packages that are not part of the `tidyverse` but which also use a common design across packages. 

An example is the [Bioconductor Project](https://www.bioconductor.org/).

--

`tidyverse` has a reputation for being easy for humans to read, and to connect tools together into reproducible workflows for manipulating, exploring, analysing and visualising rectangular data.


---
# Tidyverse

You should already have `tidyverse` installed. Packages need installing only once (unless you wish to update them) but must be loaded every session.

ðŸŽ¬ Load the core tidyverse packages with:

```r
library(tidyverse)
```

--
[Core packages](https://www.tidyverse.org/packages/) are: `ggplot2`, `dplyr`, `tidyr`, `readr`, `purr`, `tibble`, `stringr` and `forcats`

--

The tidyverse also includes many other packages with more specialised usage. They are not loaded automatically with `library(tidyverse)`and need their own `library()` calls. 
--

Examples are `readxl`, `haven`, `rvest` and `lubridate.`


---
# The pipe %&gt;%

The pipe `%&gt;%` operator from the `magrittr` package &lt;a name=cite-magrittr&gt;&lt;/a&gt;([Bache and Wickham, 2014b](#bib-magrittr)) is loaded with core tidyverse. 

It is key to connecting tools together in a readable way.

It can improve code readability by:

--

* structuring sequences of data operations left-to-right (as opposed to from the inside and out),

--

* minimizing the need for intermediates, 

--

* making it easy to add steps anywhere in the sequence of operations.

--

Instead of using ` function(object)` you can use `object %&gt;% function()`

--

This is useful when you have multiple functions to apply.

---
# The pipe %&gt;%

For example, suppose we want to apply a log-squareroot transformation&lt;sup&gt;1&lt;/sup&gt; to some proportion data. 

.footnote[1. a transformation commonly applied to proportion data to make it less platykurtic `\(x^{t} = log(\sqrt{x})\)`
]

--

ðŸŽ¬ Generate a random sample of ten proportions to work with:


```r
nums &lt;- sample((1:100)/100, size = 10, replace = FALSE)
```

--

Two ways we could apply the log-squareroot transformation are to:

1. nest the squareroot and log functions  
2. create intermediate variables  

---
# The pipe %&gt;%

ðŸŽ¬ Nest the `sqrt()` and `log()` functions:


```r
tnums &lt;- log(sqrt(nums))
```

--

Disadvantage: Code must read from inside to outside. 

Increasingly difficult to read as number of functions increases. 

Also makes simple debugging harder.

--

ðŸŽ¬ Create intermediate variables:


```r
sqrtnums &lt;- sqrt(nums)
tnums &lt;- log(sqrtnums)
```

--

Disadvantage: Extra variables you don't need. Not ideal if objects are large.

---
# The pipe %&gt;%

Using the pipe avoids these by taking the output of one operation as the input of the next. 

The pipe has long been used by Unix operating systems (where the pipe operator is `|`). 
The R pipe operator is `%&gt;%`, a short cut for which is ctrl-shift-M. 

--

ðŸŽ¬ Use pipes to code the functions in sequence:

```r
tnums &lt;- nums %&gt;% 
  sqrt() %&gt;% 
  log()
```

--

This can be read as: take `nums` and then squareroot it and then log it.

---
# The pipe %&gt;%

More explicitly, this is:


```r
tnums &lt;- nums %&gt;% 
  sqrt(.) %&gt;% 
  log(.)
```

Where `.` stands for the object being passed in. 

In most cases, you don't need to include the `.`.

Occasionally you do have to, for example when arguments are optional or there is ambiguity over which argument is meant.

---
# Converting "wide" to "long"

Data commonly need to be reshaped from a format with more than one observation per row.

--

The data given in [biomass.txt](raw_data/biomass.txt) are taken from an experiment in which the insect pest biomass (g) was measured on plots sprayed  with water (control) or one of five different insecticides. 

Also in the data file are variables indicating the replicate number and the identity of the tray in which the plant was grown.

--

ðŸŽ¬ Save a copy of this file to your `raw_data` folder and read it in.



---
# Converting "wide" to "long"

ðŸŽ¬ View the dataframe.

.scroll-output-height[


```
##    WaterControl      A      B      C      D      E rep_tray
## 1        349.80 159.14 150.07  79.95 266.74 349.80      1_x
## 2        324.07 145.89 154.38 266.39 109.54 320.07      2_x
## 3        358.57 116.34  69.50 161.16 221.11 358.57      3_x
## 4        255.21 135.16 150.68 161.43 160.04 255.21      4_y
## 5        208.49 136.63 212.59  51.24 197.54 208.49      5_y
## 6        325.73  81.77 144.02 184.38 270.40 325.73      6_y
## 7        294.66 115.66 149.79 176.16 223.51 294.66      7_z
## 8        284.72 113.92 133.96 135.90 140.59 284.72      8_z
## 9        382.56 155.28 153.01 158.96 290.08 382.56      9_z
## 10       279.02 143.89 197.60 126.16 189.18 279.02     10_z
```

]


---
# Converting "wide" to "long"

These data are in "wide" format and can be converting to "long" format using the `tidyr` package function `pivot_longer()`. 

--

`pivot_longer()` collects the values from specified columns (cols) into a single column (values_to) and creates a column to indicate the group (names_to). 

--

We want to gather the first 6 columns but the `rep_tray` column contents should be repeated.


---
# Converting "wide" to "long"

ðŸŽ¬ Gather all the columns of biomass except `rep_tray`:


```r
biomass2 &lt;- biomass %&gt;% 
  pivot_longer(names_to = "spray", 
         values_to = "mass",
         cols = -rep_tray)
```

The values will be in a column called `mass`, the treatments in a column called `spray`.


---
# Converting "wide" to "long"

ðŸŽ¬ Write this dataframe to file to your `processed_data` folder.


&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Tidy the data given in [Human development index.csv](raw_data/Human development index.csv) so that all the indices are in a single column with other columns giving the rank, country and year.


---
# Converting "wide" to "long"

ðŸŽ¬ Write this dataframe to file to your `processed_data` folder.



```r
file &lt;- "processed_data/biomass2.txt"
write.table(biomass2, file = file, row.names = FALSE, quote = FALSE)
```

You can see the resulting file here:  [biomass2.txt](processed_data/biomass2.txt) 

.scroll-output-height[


```
##    rep_tray        spray   mass
## 1       1_x WaterControl 349.80
## 2       1_x            A 159.14
## 3       1_x            B 150.07
## 4       1_x            C  79.95
## 5       1_x            D 266.74
## 6       1_x            E 349.80
## 7       2_x WaterControl 324.07
## 8       2_x            A 145.89
## 9       2_x            B 154.38
## 10      2_x            C 266.39
## 11      2_x            D 109.54
## 12      2_x            E 320.07
## 13      3_x WaterControl 358.57
## 14      3_x            A 116.34
## 15      3_x            B  69.50
## 16      3_x            C 161.16
## 17      3_x            D 221.11
## 18      3_x            E 358.57
## 19      4_y WaterControl 255.21
## 20      4_y            A 135.16
## 21      4_y            B 150.68
## 22      4_y            C 161.43
## 23      4_y            D 160.04
## 24      4_y            E 255.21
## 25      5_y WaterControl 208.49
## 26      5_y            A 136.63
## 27      5_y            B 212.59
## 28      5_y            C  51.24
## 29      5_y            D 197.54
## 30      5_y            E 208.49
## 31      6_y WaterControl 325.73
## 32      6_y            A  81.77
## 33      6_y            B 144.02
## 34      6_y            C 184.38
## 35      6_y            D 270.40
## 36      6_y            E 325.73
## 37      7_z WaterControl 294.66
## 38      7_z            A 115.66
## 39      7_z            B 149.79
## 40      7_z            C 176.16
## 41      7_z            D 223.51
## 42      7_z            E 294.66
## 43      8_z WaterControl 284.72
## 44      8_z            A 113.92
## 45      8_z            B 133.96
## 46      8_z            C 135.90
## 47      8_z            D 140.59
## 48      8_z            E 284.72
## 49      9_z WaterControl 382.56
## 50      9_z            A 155.28
## 51      9_z            B 153.01
## 52      9_z            C 158.96
## 53      9_z            D 290.08
## 54      9_z            E 382.56
## 55     10_z WaterControl 279.02
## 56     10_z            A 143.89
## 57     10_z            B 197.60
## 58     10_z            C 126.16
## 59     10_z            D 189.18
## 60     10_z            E 279.02
```

]

---
# Splitting column contents

We sometimes have single columns which contain more than one type of encoded information. 

--

For example, a column might contain a full species name and you might want to separate the genus and species names to perform a by-genus analysis.

--

Another example arises when you read in multiple files with names that encode a date, experiment or treatment. Typically, we add the file name to a column in the dataframe before combining the dataframes for analysis.

---
# Splitting column contents

For the `biomass2` data we might wish to separate the replicate number from the tray identity and put them in two separate columns. 

--


We can do this with a 'regular expression' or [regex](https://en.wikipedia.org/wiki/Regular_expression). A regex defines a pattern for matching text. 

--

It's a big topic and there are many tutorials. I remember a few bits and google "how to match ... regex". 

[A quick reference](https://www.rexegg.com/regex-quickstart.html)

---
# Splitting column contents

The `extract()` function from the `tidyr` helps us achieve this.

We give:
* the names of the new columns we want to create
* the patterns matching the part of the `rep_tray` value we want to go in each column.

--

ðŸŽ¬ Extract parts of `rep_tray` and put in new columns `replicate_number`, `tray_id`:


```r
biomass3 &lt;- biomass2 %&gt;% 
  extract(rep_tray, 
          c("replicate_number", "tray_id"),
          "([0-9]{1,2})\\_([a-z])")
```

--

* The patterns to save into columns are inside `( )`.  
* The pattern going into `replicate_number`, `[0-9]{1,2}`, means 1 or 2 numbers.  
* The pattern going into `tray_id`, `[a-z]` means one lowercase letter.
* the bit between the two `( )`, `\_` is a pattern that matches what is in `rep_tray` but is not to be saved. 

 
---
# Splitting column contents

.scroll-output-height[


```
##    replicate_number tray_id        spray   mass
## 1                 1       x WaterControl 349.80
## 2                 1       x            A 159.14
## 3                 1       x            B 150.07
## 4                 1       x            C  79.95
## 5                 1       x            D 266.74
## 6                 1       x            E 349.80
## 7                 2       x WaterControl 324.07
## 8                 2       x            A 145.89
## 9                 2       x            B 154.38
## 10                2       x            C 266.39
## 11                2       x            D 109.54
## 12                2       x            E 320.07
## 13                3       x WaterControl 358.57
## 14                3       x            A 116.34
## 15                3       x            B  69.50
## 16                3       x            C 161.16
## 17                3       x            D 221.11
## 18                3       x            E 358.57
## 19                4       y WaterControl 255.21
## 20                4       y            A 135.16
## 21                4       y            B 150.68
## 22                4       y            C 161.43
## 23                4       y            D 160.04
## 24                4       y            E 255.21
## 25                5       y WaterControl 208.49
## 26                5       y            A 136.63
## 27                5       y            B 212.59
## 28                5       y            C  51.24
## 29                5       y            D 197.54
## 30                5       y            E 208.49
## 31                6       y WaterControl 325.73
## 32                6       y            A  81.77
## 33                6       y            B 144.02
## 34                6       y            C 184.38
## 35                6       y            D 270.40
## 36                6       y            E 325.73
## 37                7       z WaterControl 294.66
## 38                7       z            A 115.66
## 39                7       z            B 149.79
## 40                7       z            C 176.16
## 41                7       z            D 223.51
## 42                7       z            E 294.66
## 43                8       z WaterControl 284.72
## 44                8       z            A 113.92
## 45                8       z            B 133.96
## 46                8       z            C 135.90
## 47                8       z            D 140.59
## 48                8       z            E 284.72
## 49                9       z WaterControl 382.56
## 50                9       z            A 155.28
## 51                9       z            B 153.01
## 52                9       z            C 158.96
## 53                9       z            D 290.08
## 54                9       z            E 382.56
## 55               10       z WaterControl 279.02
## 56               10       z            A 143.89
## 57               10       z            B 197.60
## 58               10       z            C 126.16
## 59               10       z            D 189.18
## 60               10       z            E 279.02
```

]

---
# Case study

## Overivew

You will now work through an example of some real data from [The Genever Group](https://www.geneverlab.info/). The arrangement and format of these data are typical of many protein and gene expression datasets so the processing is representative of that needed in a variety of situations.

--

The data are mass spectrometry data of the soluble protein fraction from five immortalised mesenchymal stromal cell (MSC) lines. 

The data are normalised protein abundances. Each row is a protein.

--

ðŸŽ¬ Save a copy of [Y101_Y102_Y201_Y202_Y101-5.csv](raw_data/Y101_Y102_Y201_Y202_Y101-5.csv) file to your `raw_data` folder.

ðŸŽ¬ You may wish to view it while reading the information on the next page.

---
# Case study

## Data description

The cells lines are Y101, Y102, Y201, Y202 and Y101.5 and there are three replicates for each cell line arranged in columns. Also in the file are columns for:

* the protein accession
* the number of peptides used to identify the protein
* the number of unique peptides used to identify the protein
* a measure of confidence in that identification
* the maximum fold change between the mean abundances of two cell lines (i.e., highest mean / lowest mean)
* a p value for a comparison test between the highest mean and lowest mean
* a q value (corrected p value) 
* a measure of the power of that test
* the cell line with the highest mean
* the cell line with the lowest mean
* the protein mass
* whether at least two peptides were detected for a protein.

---
# Case study

## Data Import

Column names are spread over three rows but are primarily in the third row.

--

We can read in from the third row by skipping the first two. We can also use the `clean()` function from the `janitor` package to improve the column names.


ðŸŽ¬ Read in the file using `read_csv()` from the `tidyverse`'s `readr` package.

```r
# define file name
filesol &lt;- "raw_data/Y101_Y102_Y201_Y202_Y101-5.csv"

# skip first two lines
sol &lt;- read_csv(filesol, skip = 2) %&gt;% 
  janitor::clean_names()
```

---
# Case study

## Data Import

ðŸ‘€ I used `read_csv()` because strings are treated as character variables, not factors. Whilst analysis and visualisation often require factor variables, any processing of strings is made much easier if they are characters.

--

ðŸ‘€ the `::` notation gives you access to a package's functions without first using the `library()` command. Useful when you want to use a single function from a package, or you need to specify which package when a function name is used in two loaded packages.

---
# Case study

## Filtering rows

This dataset includes bovine serum proteins from the medium on which the cells were grown which need to be filtered out.

--

We also filter out proteins for which fewer than 2 peptides were detected since we can not be confident about their identity. This is common practice for such proteomic data. 

--

ðŸŽ¬ Keep rows of human proteins identified by more than one peptide:

```r
sol &lt;- sol %&gt;% 
  filter(str_detect(description, "OS=Homo sapiens")) %&gt;% 
  filter(x1pep == "x")
```
ðŸ‘€ `str_detect(string, pattern)` returns a logical vector according to whether 'pattern' is found in 'string'.

---
# Case study

## Processing cells contents

It would be useful to extract the genename from the description and put it in a column.

One entry from the description column looks like this:

.scroll-output-width[


```r
sol$description[1]
```

```
## [1] "Neuroblast differentiation-associated protein AHNAK OS=Homo sapiens GN=AHNAK PE=1 SV=2"
```
]

--

The genename is after `GN=`. We need to extract the part of the string with the genename and put it in a new column. 

A way to problem-solve your way through this is work with *one* value carrying out one operation at a time until you've worked out what to do before implementing on an entire column.

---
# Case study

## Processing cells contents

### One step at a time on one value

ðŸŽ¬ Extract the first value of the description to work with:

```r
one_description &lt;- sol$description[1]
```

--

ðŸŽ¬ Extract the part of the string after `GN=` using a regex:

```r
str_extract(one_description,"GN=[^\\s]+")
```

```
## [1] "GN=AHNAK"
```

Explanation on next slide.

---
# Case study

## Processing cells contents

### One step at a time on one value


* `[ ]` means some characters
* `^` means 'not' when inside `[ ]`
* `\s` means white space  
* the `\` before is an escape character to indicate that the next character, `\` should not be taken literally (because it's part of `\s`)  
* `+` means one or more  

--

So `GN=[^\\s]+` means `GN=` followed by one or more characters that are not whitespace. This means the pattern stops matching at the first white space after "GN=".

---
# Case study

## Processing cells contents

### One step at a time on one value

We're close. Now we will drop the `GN=` part by replacing it with nothing:

ðŸŽ¬ Add replacing `GN=` with an empty string, `""`, to the pipeline:

```r
str_extract(one_description, "GN=[^\\s]+") %&gt;% 
  str_replace("GN=", "")
```

```
## [1] "AHNAK"
```

--
## ðŸŽˆ

---
# Case study

## Processing cells contents

### Creating a new column

`mutate()` is the `dplyr` function that adds new variables and preserves existing ones. It takes `name` = `value` pairs of expressions where `name` is the name for the new variable and `value` is the value it takes which maybe be an expression. 

--

ðŸŽ¬ Add a variable `genename` which contains the processed string from the `description` variable:

```r
sol &lt;- sol %&gt;%
  mutate(genename =  str_extract(description,"GN=[^\\s]+") %&gt;% 
           str_replace("GN=", ""))
```

---
# Case study


&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Add a column, `protid`, for the top protein identifier. This is the first Uniprot ID after the "1::" in the `accession` column. 



&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt;  Create a second dataframe, `sol2` in which the protein abundances are in a single column, `abundance` and the cell lineage and replicate, `lineage_rep`, is indicated in another. All the other variables should also be in the new data frame. You might find [`starts_with()`](https://www.rdocumentation.org/packages/tidyselect/versions/1.0.0/topics/select_helpers) useful.


&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Create separate columns in `sol2` for the cell lineage and the replicate.



---
# Case study

## Answers
&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Add a column, `protid`, for the top protein identifier. This is the first Uniprot ID after the "1::" in the `accession` column. 


```r
# trying it out on one value
accession &lt;- sol$accession[2]
str_extract(accession, "1::[^;]+") %&gt;% 
  str_replace("1::", "")
```

```
## [1] "Q15149"
```

```r
# adding a new column 
sol &lt;- sol %&gt;%
  mutate(protid =  str_extract(accession, "1::[^;]+") %&gt;% 
           str_replace("1::", ""))
```

---
# Case study

## Answers

&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Create a second dataframe, `sol2` in which the protein abundances are in a single column, `abundance` and the cell lineage and replicate, `lineage_rep`, is indicated in another. All the other variables should also be in the new data frame. 

```r
sol2 &lt;- sol %&gt;% pivot_longer(names_to = "lineage_rep",
                             values_to = "abundance",
                             cols = starts_with("y"))
```

---
# Case study

## Answers

&lt;span style=" font-weight: bold;    color: #fdf9f6 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #25496b !important;" &gt;Extra exercise:&lt;/span&gt; Create separate columns in `sol2` for the cell lineage and the replicate.


```r
sol2 &lt;- sol2 %&gt;%
  extract(lineage_rep,
          c("line", "rep"),
          "(y[0-9]{3,4})\\_([a-c])")
```




---
# Summary

.font110[

* `tidyverse` is a collection of packages with a common design; many excellent packages are not part of it  
* `library(tidyverse)` loads the core packages; other `tidyverse` packages need their own `library()` call  
* the pipe `%&gt;%` is key to connecting `tidyverse` tools together to create highly readable code  
* reshaping data from wide to long format is common: `pivot_longer()`  
* splitting cell contents is common: `extract()` 
* regular expressions allow you to match text patterns; expect to have to google and do a lot of trial and error  
* `clean_names()`  
* `::` gives you access to a package's functions without using `library()`  
* use particular rows `filter()`  
* use particular columns `select()`  

]

---
# References
.footnote[
Slides made with with xaringan &lt;a name=cite-xaringan&gt;&lt;/a&gt;([Xie, 2019](#bib-xaringan))

]

&lt;a name=bib-magrittr&gt;&lt;/a&gt;[Bache, S. M. and H. Wickham](#cite-magrittr)
(2014b). _magrittr: A Forward-Pipe Operator for R_. R package version
1.5. URL:
[https://CRAN.R-project.org/package=magrittr](https://CRAN.R-project.org/package=magrittr).

&lt;a name=bib-R-tidyverse&gt;&lt;/a&gt;[Wickham, H.](#cite-R-tidyverse) (2017).
_tidyverse: Easily Install and Load the 'Tidyverse'_. R package version
1.2.1. URL:
[https://CRAN.R-project.org/package=tidyverse](https://CRAN.R-project.org/package=tidyverse).

&lt;a name=bib-Wickham2019-ml&gt;&lt;/a&gt;[Wickham, H, M. Averick, et
al.](#cite-Wickham2019-ml) (2019). "Welcome to the Tidyverse". In:
_JOSS_ 4.43, p. 1686.

&lt;a name=bib-xaringan&gt;&lt;/a&gt;[Xie, Y.](#cite-xaringan) (2019). _xaringan:
Presentation Ninja_. R package version 0.12. URL:
[https://CRAN.R-project.org/package=xaringan](https://CRAN.R-project.org/package=xaringan).



---

class: inverse

# ðŸŽ‰ Congratulations! Keep practising! ðŸŽ‰ 

---
# Introduction to Reproducibility in R

## Emma Rand &lt;br&gt; [emma.rand@york.ac.uk](mailto:emma.rand@york.ac.uk) &lt;br&gt; Twitter: [@er13_r](https://twitter.com/er13_r) &lt;br&gt; GitHub: [3mmaRand](https://github.com/3mmaRand)  &lt;br&gt; blog: https://buzzrbeeline.blog/
&lt;br&gt;
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"&gt;White Rose BBSRC Doctoral Training Partnership (DTP) in Mechanistic Biology Analytics 1: Introduction to reproducible analyses in R&lt;/span&gt; by &lt;span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"&gt;Emma Rand&lt;/span&gt; is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
